---
output-file: matrix_multiplication.html
title: Matrix Multiplication

---



<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

## Brute Force Methodology

This approach uses the most basic and straightforward method of matrix multiplication, directly applying the definition outlined above.

---

[source](https://github.com/teja00/BuildingBlocks/blob/main/BuildingBlocks/matrix_multiply.py#L12){target="_blank" style="float:right; font-size:smaller"}

### matrix_multiply

>      matrix_multiply (a:List[List[float]], b:List[List[float]])

|    | **Type** | **Details** |
| -- | -------- | ----------- |
| a | typing.List[typing.List[float]] | input matrix of size (m, n) |
| b | typing.List[typing.List[float]] | input matrix of size (n, p) |
| **Returns** | **typing.List[typing.List[float]]** | **output matrix of size (m, p)** |


::: {#df123dc8 .cell}
``` {.python .cell-code code-fold="show" code-summary="Exported source"}
def matrix_multiply(a: List[List[float]], # input matrix of size (m, n)
                    b: List[List[float]] # input matrix of size (n, p)
                    ) -> List[List[float]]: # output matrix of size (m, p)
    a = np.array(a)
    b = np.array(b)
    ar, ac = a.shape
    br, bc = b.shape
    if ac != br:
        raise ValueError("Incompatible shapes for matrix multiplication")
    result = np.zeros((ar, bc))
    for i in range(ar):
        for j in range(bc):
            for k in range(ac): # or br works too
                result[i][j] += a[i][k] * b[k][j]
    return result.tolist()
```
:::


## PyTorch Optimization

PyTorch leverages **ATen**, a high-performance tensor library written in C++. At its core, PyTorch optimizes matrix multiplication by utilizing efficient element-wise operations and parallel computation under the hood. These low-level implementations significantly accelerate the computation.  

Letâ€™s now rewrite the above matrix multiplication using PyTorch's element-wise operations to take advantage of this optimization.

---

### matrix_multiply_torch

>      matrix_multiply_torch (a:List[List[float]], b:List[List[float]])

|    | **Type** | **Details** |
| -- | -------- | ----------- |
| a | typing.List[typing.List[float]] | input matrix of size (m, n) |
| b | typing.List[typing.List[float]] | input matrix of size (n, p) |
| **Returns** | **typing.List[typing.List[float]]** | **output matrix of size (m, p)** |


::: {#02e06b22 .cell}
``` {.python .cell-code code-fold="show" code-summary="Exported source"}
def matrix_multiply_torch(a: List[List[float]], # input matrix of size (m, n)
                          b: List[List[float]] # input matrix of size (n, p)
                        ) -> List[List[float]]: # output matrix of size (m, p)
        a = torch.tensor(a)
        b = torch.tensor(b)
        ar, ac = a.shape
        br, bc = b.shape
        if ac != br:
            raise ValueError("Incompatible shapes for matrix multiplication")
        result = torch.zeros((ar, bc))
        for i in range(ar):
            for j in range(bc):
                result[i][j] = torch.sum(a[i, :] * b[:, j])
        return result
```
:::


